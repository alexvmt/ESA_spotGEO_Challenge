{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n",
    "\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def read_image(path):\n",
    "    return plt.imread(path)\n",
    "\n",
    "def read_annotation_file(path):\n",
    "    with open(path) as annotation_file:\n",
    "        annotation_list = json.load(annotation_file)\n",
    "    # Transform list of annotations into dictionary\n",
    "    annotation_dict = {}\n",
    "    for annotation in annotation_list:\n",
    "        sequence_id = annotation['sequence_id']\n",
    "        if sequence_id not in annotation_dict:\n",
    "            annotation_dict[sequence_id] = {}\n",
    "        annotation_dict[sequence_id][annotation['frame']] = annotation['object_coords']\n",
    "    return annotation_dict\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def random_different_coordinates(coords, size_x, size_y, pad):\n",
    "    \"\"\" Returns a random set of coordinates that is different from the provided coordinates, \n",
    "    within the specified bounds.\n",
    "    The pad parameter avoids coordinates near the bounds.\"\"\"\n",
    "    good = False\n",
    "    while not good:\n",
    "        good = True\n",
    "        c1 = random.randint(pad + 1, size_x - (pad + 1))\n",
    "        c2 = random.randint(pad + 1, size_y -( pad + 1))\n",
    "        for c in coords:\n",
    "            if c1 == c[0] and c2 == c[1]:\n",
    "                good = False\n",
    "                break\n",
    "    return (c1,c2)\n",
    "\n",
    "def extract_neighborhood(x, y, arr, radius):\n",
    "    \"\"\" Returns a 1-d array of the values within a radius of the x,y coordinates given \"\"\"\n",
    "    return arr[(x - radius) : (x + radius + 1), (y - radius) : (y + radius + 1)].ravel()\n",
    "\n",
    "def check_coordinate_validity(x, y, size_x, size_y, pad):\n",
    "    \"\"\" Check if a coordinate is not too close to the image edge \"\"\"\n",
    "    return x >= pad and y >= pad and x + pad < size_x and y + pad < size_y\n",
    "\n",
    "def generate_labeled_data(image_path, annotation, nb_false, radius):\n",
    "    \"\"\" For one frame and one annotation array, returns a list of labels \n",
    "    (1 for true object and 0 for false) and the corresponding features as an array.\n",
    "    nb_false controls the number of false samples\n",
    "    radius defines the size of the sliding window (e.g. radius of 1 gives a 3x3 window)\"\"\"\n",
    "    features,labels = [],[]\n",
    "    im_array = read_image(image_path)\n",
    "    # True samples\n",
    "    for obj in annotation:\n",
    "        obj = [int(x + .5) for x in obj] #Project the floating coordinate values onto integer pixel coordinates.\n",
    "        # For some reason the order of coordinates is inverted in the annotation files\n",
    "        if check_coordinate_validity(obj[1],obj[0],im_array.shape[0],im_array.shape[1],radius):\n",
    "            features.append(extract_neighborhood(obj[1],obj[0],im_array,radius))\n",
    "            labels.append(1)\n",
    "    # False samples\n",
    "    for i in range(nb_false):\n",
    "        c = random_different_coordinates(annotation,im_array.shape[1],im_array.shape[0],radius)\n",
    "        features.append(extract_neighborhood(c[1],c[0],im_array,radius))\n",
    "        labels.append(0)\n",
    "    return np.array(labels),np.stack(features,axis=1)\n",
    "\n",
    "def generate_labeled_set(annotation_array, path, sequence_id_list, radius, nb_false):\n",
    "    # Generate labeled data for a list of sequences in a given path\n",
    "    labels,features = [],[]\n",
    "    for seq_id in sequence_id_list:\n",
    "        for frame_id in range(1,6):\n",
    "            d = generate_labeled_data(f\"{path}{seq_id}/{frame_id}.png\",\n",
    "                                    annotation_array[seq_id][frame_id],\n",
    "                                    nb_false,\n",
    "                                    radius)\n",
    "            labels.append(d[0])\n",
    "            features.append(d[1])\n",
    "    return np.concatenate(labels,axis=0), np.transpose(np.concatenate(features,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prepartation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotation = read_annotation_file('../input/spotgeo/train_anno.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "radius = 3\n",
    "train_labels, train_features = generate_labeled_set(train_annotation, '../input/spotgeo/train/train/', range(1,1001), radius, 10)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "validation_labels, validation_features = generate_labeled_set(train_annotation, '../input/spotgeo/train/train/', range(1001,1280), radius, 10)\n",
    "\n",
    "print(validation_labels.shape)\n",
    "print(validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaludate random forest\n",
    "\n",
    "pred_labels = model.predict(validation_features)\n",
    "\n",
    "print(classification_report(pred_labels, validation_labels))\n",
    "print('\\n')\n",
    "print(confusion_matrix(pred_labels, validation_labels))\n",
    "print('\\n')\n",
    "print(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mnist\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(im, model, radius):\n",
    "    n_features=(2*radius+1)**2 #Total number of pixels in the neighborhood\n",
    "    feat_array=np.zeros((im.shape[0],im.shape[1],n_features))\n",
    "    for x in range(radius+1,im.shape[0]-(radius+1)):\n",
    "        for y in range(radius+1,im.shape[1]-(radius+1)):\n",
    "            feat_array[x,y,:]=extract_neighborhood(x,y,im,radius)\n",
    "    all_pixels=feat_array.reshape(im.shape[0]*im.shape[1],n_features)\n",
    "    pred_pixels=model.predict(all_pixels).astype(np.bool_)\n",
    "    pred_image=pred_pixels.reshape(im.shape[0],im.shape[1])\n",
    "    return pred_image\n",
    "\n",
    "def extract_centroids(pred, bg):\n",
    "    conn_comp=measure.label(pred, background=bg)\n",
    "    object_dict=defaultdict(list) #Keys are the indices of the connected components and values are arrrays of their pixel coordinates \n",
    "    for (x,y),label in np.ndenumerate(conn_comp):\n",
    "            if label != bg:\n",
    "                object_dict[label].append([x,y])\n",
    "    # Mean coordinate vector for each object, except the \"0\" label which is the background\n",
    "    centroids={label: np.mean(np.stack(coords),axis=0) for label,coords in object_dict.items()}\n",
    "    object_sizes={label: len(coords) for label,coords in object_dict.items()}\n",
    "    return centroids, object_sizes\n",
    "\n",
    "def filter_large_objects(centroids,object_sizes, max_size):\n",
    "    small_centroids={}\n",
    "    for label,coords in centroids.items():\n",
    "            if object_sizes[label] <= max_size:\n",
    "                small_centroids[label]=coords\n",
    "    return small_centroids\n",
    "\n",
    "def predict_objects(sequence_id, frame_id, model, radius, max_size):\n",
    "    print(f'sequence_id: {sequence_id}')\n",
    "    test_image = plt.imread(f\"../input/spotgeo/test/test/{sequence_id}/{frame_id}.png\")\n",
    "    test_pred=classify_image(test_image, model, radius)\n",
    "    test_centroids, test_sizes = extract_centroids(test_pred, 0)\n",
    "    test_centroids = filter_large_objects(test_centroids, test_sizes, max_size)\n",
    "    # Switch x and y coordinates for submission\n",
    "    if len(test_centroids.values()) > 0:\n",
    "        sub=np.concatenate([c[np.array([1,0])].reshape((1,2)) for c in test_centroids.values()])\n",
    "        #np array converted to list for json seralization, truncated to the first 30 elements\n",
    "        return sub.tolist()[0:30]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#sub_list = predict_objects(1, 1, model, radius, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_id = 1\n",
    "#frame_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = []\n",
    "\n",
    "#for s in range(1,5121):\n",
    "#    for fr in range(1,6):\n",
    "#        if s == sequence_id and fr == frame_id:\n",
    "#            submission.append({\"sequence_id\" : s,\n",
    "#                               \"frame\" : fr,\n",
    "#                               \"num_objects\" : len(sub_list),\n",
    "#                               \"object_coords\" : sub_list})\n",
    "#        else:\n",
    "#            submission.append({\"sequence_id\" : s,\n",
    "#                               \"frame\" : fr,\n",
    "#                               \"num_objects\" : 0,\n",
    "#                               \"object_coords\" : []})\n",
    "#\n",
    "#with open('/kaggle/working/my_submission.json', 'w') as outfile:\n",
    "#    json.dump(submission, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "nb_procs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "p = Pool(processes=nb_procs)\n",
    "sequence_list, frame_list = np.arange(1, 5121), np.arange(1, 6)\n",
    "id_pair_list = list(itertools.product(sequence_list, frame_list))\n",
    "sub_sequence = p.starmap(predict_objects, [(id_pair[0], id_pair[1], model, radius, 1) for id_pair in id_pair_list])\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sub_dict = {id_pair: sub for id_pair,sub in zip(id_pair_list, sub_sequence)}\n",
    "\n",
    "submission=[]\n",
    "for id_pair,sub_list in sub_dict.items():\n",
    "           submission.append({\"sequence_id\" : int(id_pair[0]), \n",
    "                                    \"frame\" : int(id_pair[1]), \n",
    "                                    \"num_objects\" : len(sub_list), \n",
    "                                    \"object_coords\" : sub_list})\n",
    "with open('/kaggle/working/my_submission.json', 'w') as outfile:\n",
    "    json.dump(submission, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
