{"cells":[{"metadata":{"_uuid":"6ed2312e-4fb4-4d4f-bb8b-259e7c1c1e33","_cell_guid":"c0d34db8-be25-43c1-9750-300fbf4cf443","trusted":true},"cell_type":"markdown","source":"## setup","execution_count":null},{"metadata":{"_uuid":"529e7d75-c836-487e-8e68-14fb53f0cc18","_cell_guid":"10f0e46b-3649-45e8-b4db-4e45f5c45186","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\n\nfrom collections import defaultdict\n\nimport json\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n\nimport itertools\n\nimport random\n\nfrom skimage import measure\n\nimport pickle\n\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcbb33fe-c732-46d6-9d24-f5b87e810363","_cell_guid":"8c8b4026-470a-4d9c-93df-77de75188f0d","trusted":true},"cell_type":"code","source":"def read_image(path):\n    return plt.imread(path)\n\ndef read_annotation_file(path):\n    with open(path) as annotation_file:\n        annotation_list = json.load(annotation_file)\n    # Transform list of annotations into dictionary\n    annotation_dict = {}\n    for annotation in annotation_list:\n        sequence_id = annotation['sequence_id']\n        if sequence_id not in annotation_dict:\n            annotation_dict[sequence_id] = {}\n        annotation_dict[sequence_id][annotation['frame']] = annotation['object_coords']\n    return annotation_dict\n\nrandom.seed(0)\n\ndef random_different_coordinates(coords, size_x, size_y, pad):\n    \"\"\" Returns a random set of coordinates that is different from the provided coordinates, \n    within the specified bounds.\n    The pad parameter avoids coordinates near the bounds.\"\"\"\n    good = False\n    while not good:\n        good = True\n        c1 = random.randint(pad + 1, size_x - (pad + 1))\n        c2 = random.randint(pad + 1, size_y -( pad + 1))\n        for c in coords:\n            if c1 == c[0] and c2 == c[1]:\n                good = False\n                break\n    return (c1,c2)\n\ndef extract_neighborhood(x, y, arr, radius):\n    \"\"\" Returns a 1-d array of the values within a radius of the x,y coordinates given \"\"\"\n    return arr[(x - radius) : (x + radius + 1), (y - radius) : (y + radius + 1)].ravel()\n\ndef check_coordinate_validity(x, y, size_x, size_y, pad):\n    \"\"\" Check if a coordinate is not too close to the image edge \"\"\"\n    return x >= pad and y >= pad and x + pad < size_x and y + pad < size_y\n\ndef generate_labeled_data(image_path, annotation, nb_false, radius):\n    \"\"\" For one frame and one annotation array, returns a list of labels \n    (1 for true object and 0 for false) and the corresponding features as an array.\n    nb_false controls the number of false samples\n    radius defines the size of the sliding window (e.g. radius of 1 gives a 3x3 window)\"\"\"\n    features,labels = [],[]\n    im_array = read_image(image_path)\n    # True samples\n    for obj in annotation:\n        obj = [int(x + .5) for x in obj] #Project the floating coordinate values onto integer pixel coordinates.\n        # For some reason the order of coordinates is inverted in the annotation files\n        if check_coordinate_validity(obj[1],obj[0],im_array.shape[0],im_array.shape[1],radius):\n            features.append(extract_neighborhood(obj[1],obj[0],im_array,radius))\n            labels.append(1)\n    # False samples\n    for i in range(nb_false):\n        c = random_different_coordinates(annotation,im_array.shape[1],im_array.shape[0],radius)\n        features.append(extract_neighborhood(c[1],c[0],im_array,radius))\n        labels.append(0)\n    return np.array(labels),np.stack(features,axis=1)\n\ndef generate_labeled_set(annotation_array, path, sequence_id_list, radius, nb_false):\n    # Generate labeled data for a list of sequences in a given path\n    labels,features = [],[]\n    for seq_id in sequence_id_list:\n        for frame_id in range(1,6):\n            d = generate_labeled_data(f\"{path}{seq_id}/{frame_id}.png\",\n                                    annotation_array[seq_id][frame_id],\n                                    nb_false,\n                                    radius)\n            labels.append(d[0])\n            features.append(d[1])\n    return np.concatenate(labels,axis=0), np.transpose(np.concatenate(features,axis=1))\n\ndef classify_image(im, model, radius):\n    n_features=(2*radius+1)**2 #Total number of pixels in the neighborhood\n    feat_array=np.zeros((im.shape[0],im.shape[1],n_features))\n    for x in range(radius+1,im.shape[0]-(radius+1)):\n        for y in range(radius+1,im.shape[1]-(radius+1)):\n            feat_array[x,y,:]=extract_neighborhood(x,y,im,radius)\n    all_pixels=feat_array.reshape(im.shape[0]*im.shape[1],n_features)\n    pred_pixels=model.predict(all_pixels).astype(np.bool_)\n    pred_image=pred_pixels.reshape(im.shape[0],im.shape[1])\n    return pred_image\n\ndef extract_centroids(pred, bg):\n    conn_comp=measure.label(pred, background=bg)\n    object_dict=defaultdict(list) #Keys are the indices of the connected components and values are arrrays of their pixel coordinates \n    for (x,y),label in np.ndenumerate(conn_comp):\n            if label != bg:\n                object_dict[label].append([x,y])\n    # Mean coordinate vector for each object, except the \"0\" label which is the background\n    centroids={label: np.mean(np.stack(coords),axis=0) for label,coords in object_dict.items()}\n    object_sizes={label: len(coords) for label,coords in object_dict.items()}\n    return centroids, object_sizes\n\ndef filter_large_objects(centroids,object_sizes, max_size):\n    small_centroids={}\n    for label,coords in centroids.items():\n            if object_sizes[label] <= max_size:\n                small_centroids[label]=coords\n    return small_centroids\n\ndef predict_objects(sequence_id, frame_id, model, radius, max_size):\n    test_image = plt.imread(f\"../input/spotgeo/test/test/{sequence_id}/{frame_id}.png\")\n    test_pred=classify_image(test_image, model, radius)\n    test_centroids, test_sizes = extract_centroids(test_pred, 0)\n    test_centroids = filter_large_objects(test_centroids, test_sizes, max_size)\n    # Switch x and y coordinates for submission\n    if len(test_centroids.values()) > 0:\n        sub=np.concatenate([c[np.array([1,0])].reshape((1,2)) for c in test_centroids.values()])\n        #np array converted to list for json seralization, truncated to the first 30 elements\n        return sub.tolist()[0:30]\n    else:\n        return []","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49fbd5cd-e05c-4b5a-b04f-d5735c33891f","_cell_guid":"824b521f-2337-4031-87fa-c9b55a3bb342","trusted":true},"cell_type":"markdown","source":"## data preparation","execution_count":null},{"metadata":{"_uuid":"80c8bfe9-6aa5-49c8-9287-f571d16ad0c7","_cell_guid":"d408e6cf-8928-4505-99c3-58d28900d9b5","trusted":true},"cell_type":"code","source":"random_state = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47537c61-f53c-44f4-b809-5fb2d26743d9","_cell_guid":"6bf2932a-c82f-4ccb-9ff4-7890d52d7c56","trusted":true},"cell_type":"code","source":"train_annotation = read_annotation_file('../input/spotgeo/train_anno.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_annotation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c50efac-8ddf-4dcb-aa92-79b110ea0f4a","_cell_guid":"b41dc0c3-f24f-488e-84e4-5df30b1828cc","trusted":true},"cell_type":"code","source":"%%time\n\nradius = 3\ntrain_labels, train_features = generate_labeled_set(train_annotation, '../input/spotgeo/train/train/', range(1,1001), radius, 10)\n\nprint(train_labels.shape)\nprint(train_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32cf7a6d-0a60-4a1a-b0ba-d552b84a6419","_cell_guid":"83d9851c-2ad1-45fa-841a-a391c4d1d5cc","trusted":true},"cell_type":"code","source":"%%time\n\nvalidation_labels, validation_features = generate_labeled_set(train_annotation, '../input/spotgeo/train/train/', range(1001,1281), radius, 10)\n\nprint(validation_labels.shape)\nprint(validation_features.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train random forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(random_state = random_state, n_jobs = -1)\n\nmodel.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels = model.predict(validation_features)\n\nprint(classification_report(pred_labels, validation_labels))\nprint('\\n')\nprint(confusion_matrix(pred_labels, validation_labels))\nprint('\\n')\nprint(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [10,20,50,100,250,500,750,1000]\n\nmax_features = ['auto', 'sqrt']\n\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\nmin_samples_split = [2, 5, 10]\n\nmin_samples_leaf = [1, 2, 4]\n\nbootstrap = [True, False]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nrf = RandomForestClassifier()\n\nrf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=10, cv=3, verbose=2, random_state=random_state, n_jobs=-1, scoring='f1')\n\nrf_random.fit(train_features[:10000], train_labels[:10000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators = rf_random.best_params_['n_estimators'],\n                               max_features = rf_random.best_params_['max_features'],\n                               max_depth = rf_random.best_params_['max_depth'],\n                               min_samples_split = rf_random.best_params_['min_samples_split'],\n                               min_samples_leaf = rf_random.best_params_['min_samples_leaf'],\n                               bootstrap = rf_random.best_params_['bootstrap'],\n                               n_jobs = -1,\n                               random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model, open('/kaggle/working/rf.sav', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels = model.predict(validation_features)\n\nprint(classification_report(pred_labels, validation_labels))\nprint('\\n')\nprint(confusion_matrix(pred_labels, validation_labels))\nprint('\\n')\nprint(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nsub_list=predict_objects(1,1,model,radius,1)\nprint(sub_list[0:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"727a2e93-5550-4715-95a5-56a330fc37b1","_cell_guid":"981fd2e0-d27e-4cc4-a705-2e4e78e0742d","trusted":true},"cell_type":"markdown","source":"## train xgb","execution_count":null},{"metadata":{"_uuid":"426a8582-db51-4bc1-bbac-309c60548701","_cell_guid":"5922f97d-6fe7-45aa-a54c-86ddbb5d4f55","trusted":true},"cell_type":"code","source":"%%time\n\nimport xgboost as xgb\n\nmodel = xgb.XGBClassifier(random_state = random_state, n_jobs = -1)\n\nmodel.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels = model.predict(validation_features)\n\nprint(classification_report(pred_labels, validation_labels))\nprint('\\n')\nprint(confusion_matrix(pred_labels, validation_labels))\nprint('\\n')\nprint(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [10,20,50,100,250,500,750,1000]\n\nlearning_rate = [0.1,0.05,0.01,0.005,0.001]\n\nmax_depth = [3,4,5,6,7]\n\ncolsample_bytree = [0.7,0.8,0.9,1]\n\nsubsample = [0.7,0.8,0.9,1]\n\ngamma = [0,1,5]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'learning_rate': learning_rate,\n               'max_depth': max_depth,\n               'colsample_bytree': colsample_bytree,\n               'subsample': subsample,\n               'gamma': gamma}\n\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nimport xgboost as xgb\n\nxgb = xgb.XGBClassifier()\n\nxgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = random_grid, n_iter = 10, cv = 3, verbose = 2, random_state = random_state, n_jobs = -1, scoring = 'f1')\n\nxgb_random.fit(train_features[:10000], train_labels[:10000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nmodel = xgb.XGBClassifier(n_estimators = xgb_random.best_params_['n_estimators'],\n                          learning_rate = xgb_random.best_params_['learning_rate'],\n                          max_depth = xgb_random.best_params_['max_depth'],\n                          colsample_bytree = xgb_random.best_params_['colsample_bytree'],\n                          subsample = xgb_random.best_params_['subsample'],\n                          gamma = xgb_random.best_params_['gamma'],\n                          n_jobs = -1,\n                          random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model, open('/kaggle/working/xgb.sav', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels = model.predict(validation_features)\n\nprint(classification_report(pred_labels, validation_labels))\nprint('\\n')\nprint(confusion_matrix(pred_labels, validation_labels))\nprint('\\n')\nprint(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nsub_list=predict_objects(1,1,model,radius,1)\nprint(sub_list[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train 5-layer neural net (sklearn)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.neural_network import MLPClassifier\n\ndim = train_features.shape[1]\n\nmodel = MLPClassifier(hidden_layer_sizes=(dim,dim,dim), activation = 'relu', solver='adam', random_state=random_state)\n\nmodel.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model, open('/kaggle/working/nn5.sav', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9c9dda6-9325-4d0b-9ce1-5728d2a8322c","_cell_guid":"b505c52f-dae4-46fa-aad0-62fa778f8494","trusted":true},"cell_type":"code","source":"pred_labels = model.predict(validation_features)\n\nprint(classification_report(pred_labels, validation_labels))\nprint('\\n')\nprint(confusion_matrix(pred_labels, validation_labels))\nprint('\\n')\nprint(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e11a612-755c-40ca-a32e-eb2438aef459","_cell_guid":"5b26307b-c61a-4efa-9d18-2bc34346dc91","trusted":true},"cell_type":"code","source":"%%time\n\nsub_list=predict_objects(1,1,model,radius,1)\nprint(sub_list[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train 5-layer neural net (keras)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import backend as K\n\ndim = train_features.shape[1]\n\nmodel = Sequential()\nmodel.add(Dense(dim, input_dim=dim, activation='relu'))\nmodel.add(Dropout(0.2, seed=random_state))\nmodel.add(Dense(dim, activation='relu'))\nmodel.add(Dropout(0.2, seed=random_state))\nmodel.add(Dense(dim, activation='relu'))\nmodel.add(Dropout(0.2, seed=random_state))\nmodel.add(Dense(dim, activation='relu'))\nmodel.add(Dropout(0.2, seed=random_state))\nmodel.add(Dense(1, activation='linear'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.config.list_physical_devices('GPU')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nepochs = 100\nbatch_size = 32\n\nhistory = model.fit(train_features, train_labels, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(validation_features, validation_labels))\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/nn5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['f1'])\nplt.title('F1')\nplt.ylabel('F1')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_labels = model.predict_classes(validation_features)\n\nprint(classification_report(pred_labels, validation_labels))\nprint('\\n')\nprint(confusion_matrix(pred_labels, validation_labels))\nprint('\\n')\nprint(\"Kappa =\", cohen_kappa_score(pred_labels, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify_image(im, model, radius):\n    n_features=(2*radius+1)**2 #Total number of pixels in the neighborhood\n    feat_array=np.zeros((im.shape[0],im.shape[1],n_features))\n    for x in range(radius+1,im.shape[0]-(radius+1)):\n        for y in range(radius+1,im.shape[1]-(radius+1)):\n            feat_array[x,y,:]=extract_neighborhood(x,y,im,radius)\n    all_pixels=feat_array.reshape(im.shape[0]*im.shape[1],n_features)\n    pred_pixels=model.predict_classes(all_pixels).astype(np.bool_)\n    pred_image=pred_pixels.reshape(im.shape[0],im.shape[1])\n    return pred_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nsub_list=predict_objects(1,1,model,radius,1)\nprint(sub_list[0:5])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}